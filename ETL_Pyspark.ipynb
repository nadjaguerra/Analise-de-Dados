 {
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4xuZk93oz236",
        "QnqGTXmf0_3H",
        "dYPpbwzi5PTE",
        "ADiDBzGjBVOG"
      ],
      "authorship_tag": "ABX9TyPzSsTgLl9xZwkvbZXvQHLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadjaguerra/SoulCode-Bootamp/blob/main/ETL_Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ETL com PySpark**\n"
      ],
      "metadata": {
        "id": "VnaNnsCczch6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solicitação**\n",
        "\n",
        "ETL no conjunto de dados usando PySpark"
      ],
      "metadata": {
        "id": "4xuZk93oz236"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dicionário de Dados\n",
        "\n",
        "*  RowNumber: Número da linha no conjunto de dados.\n",
        "*  CustomerId: Identificação única do cliente.\n",
        "*  Surname: Sobrenome do cliente.\n",
        "*  CreditScore: Pontuação de crédito do cliente, uma medida de sua credibilidade financeira.\n",
        "*  Geography: Localização geográfica do cliente (por exemplo, país ou região).\n",
        "*  Gender: Gênero do cliente.\n",
        "*  Age: Idade do cliente.\n",
        "*  Tenure: Tempo que o cliente permaneceu como cliente (em anos).\n",
        "*  Balance: Saldo na conta do cliente.\n",
        "*  NumOfProducts: Número de produtos financeiros que o cliente possui.\n",
        "*  HasCrCard: Indicação se o cliente possui um cartão de crédito (1 para \"sim\", 0 para \"não\").\n",
        "*  IsActiveMember: Indicação se o cliente é um membro ativo (1 para \"sim\", 0 para \"não\").\n",
        "*  EstimatedSalary: Salário estimado do cliente.\n",
        "*  Exited: Indicação se o cliente encerrou sua conta ou não (1 para \"sim\", 0 para \"não\").\n",
        "\n",
        "Fonte: https://www.kaggle.com/datasets/mervetorkan/churndataset"
      ],
      "metadata": {
        "id": "DP6n_2TK0UKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Infraestrutura**"
      ],
      "metadata": {
        "id": "QnqGTXmf0_3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdjIWE8ArWhm",
        "outputId": "d1e7ed8e-32f9-4ae0-f2ce-06b83b3ec95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Abertura Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação da biblioteca\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0qFVHQW09Qw",
        "outputId": "5c836ca4-decb-4232-ebf6-a92574b374eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=d5659c9445a2e52ded97266acc3a644fa3869af78cf796d981176532a0a21e95\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Abertura de biblioteca\n",
        "from pyspark.sql import SparkSession    # utilizado para criação da sessão pyspark no colab\n",
        "from pyspark.sql.functions import col, when"
      ],
      "metadata": {
        "id": "rcZvds6p1K4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando ambiente\n",
        "spark = (SparkSession.builder.master('local')                 # máquina local do colab\n",
        "                             .appName('comandos_basicos')     # Nome da aplicação\n",
        "                             .config('spark.ui.port', '4050') # Porta padrão do colab;\n",
        "                             .getOrCreate())"
      ],
      "metadata": {
        "id": "zflSDJdj1YKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando o ambiente criado\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ClIXT17f13yI",
        "outputId": "73811a2c-fde0-40b2-9a6e-a6d5e6cab7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d8c78122ce0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6893231a6ca4:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>comandos_basicos</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extração\n",
        "df = (spark.read.format('csv')\n",
        "                .option('delimiter', ',')\n",
        "                .option('header', 'true')\n",
        "                .option('inferschema', 'true')\n",
        "                .load('/content/drive/MyDrive/BootCamp Análise de Dados/PySpark/churn.csv'))"
      ],
      "metadata": {
        "id": "miYcgXGi2LIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando a conjunto de dados\n",
        "df.show()"
      ],
      "metadata": {
        "id": "hbtZCyMp3Y9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pré-Análise**"
      ],
      "metadata": {
        "id": "dYPpbwzi5PTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização do conjunto de dados\n",
        "df.show()"
      ],
      "metadata": {
        "id": "IcC5v1Ja5T9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização do cabeçalho\n",
        "df.head()"
      ],
      "metadata": {
        "id": "owFf4LTU5bdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mesmos dados de cima porem em tabela\n",
        "total_rows = df.count()\n",
        "df.limit(1).show(total_rows + 1)"
      ],
      "metadata": {
        "id": "yfzgZhdQ6ppw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as últimas posições do DataFrame\n",
        "# Não há um método tail() direto em PySpark, você pode usar count()\n",
        "# para determinar o número total de linhas e então mostrar as últimas linhas\n",
        "total_rows = df.count()\n",
        "df.limit(5).show(total_rows - 5)"
      ],
      "metadata": {
        "id": "TNDsNru85ylp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização do DataFrame de forma aleatória\n",
        "df.sample(False, 0.1).show(4)  # 0.1 indica a fração das linhas a serem amostradas"
      ],
      "metadata": {
        "id": "rNTiX3h16Wt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o tamanho do DataFrame (linhas, colunas)\n",
        "(df.count(), len(df.columns))"
      ],
      "metadata": {
        "id": "ePYnswow-9SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o tipo de dados de cada coluna\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "zwyTgkAq_ha_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar as observações em cada coluna\n",
        "column_counts = [(col, df.select(col).count()) for col in df.columns]\n",
        "\n",
        "# Exibir os resultados\n",
        "for col, count in column_counts:\n",
        "    print(f\"{col}: {count}\")"
      ],
      "metadata": {
        "id": "S86CxW2pAfew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informações detalhadas do conjunto de dados\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "kNUijzGlBASF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transformação**"
      ],
      "metadata": {
        "id": "ADiDBzGjBVOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização do conjunto de dados\n",
        "df.show()"
      ],
      "metadata": {
        "id": "czEl9InxBtNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear as colunas\n",
        "df = df \\\n",
        "    .withColumnRenamed(\"RowNumber\", \"numero_linha\") \\\n",
        "    .withColumnRenamed(\"CustomerId\", \"id\") \\\n",
        "    .withColumnRenamed(\"Surname\", \"sobrenome\") \\\n",
        "    .withColumnRenamed(\"CreditScore\", \"pontuacao_credito\") \\\n",
        "    .withColumnRenamed(\"Geography\", \"localizacao\") \\\n",
        "    .withColumnRenamed(\"Gender\", \"genero\") \\\n",
        "    .withColumnRenamed(\"Age\", \"idade\") \\\n",
        "    .withColumnRenamed(\"Tenure\", \"tempo_permanencia\") \\\n",
        "    .withColumnRenamed(\"Balance\", \"saldo\") \\\n",
        "    .withColumnRenamed(\"NumOfProducts\", \"num_produtos\") \\\n",
        "    .withColumnRenamed(\"HasCrCard\", \"tem_cartao_credito\") \\\n",
        "    .withColumnRenamed(\"IsActiveMember\", \"membro_ativo\") \\\n",
        "    .withColumnRenamed(\"EstimatedSalary\", \"salario_estimado\") \\\n",
        "    .withColumnRenamed(\"Exited\", \"encerrou_conta\")"
      ],
      "metadata": {
        "id": "8xUkjOK4Cd2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização do conjunto de dados\n",
        "df.show()"
      ],
      "metadata": {
        "id": "bKlx8kXQChH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Valores nulos**"
      ],
      "metadata": {
        "id": "1QCIHRM3DMJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores nulos em cada coluna\n",
        "for column in df.columns:\n",
        "    null_count = df.filter(df[column].isNull()).count()\n",
        "    print(f\"{column}: {null_count} nulos\")"
      ],
      "metadata": {
        "id": "pBHMmiKBDLRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes de eliminar de vez, por favor filtre os dados\n",
        "# Eliminação de dados nulos - como não tem deixei comentado\n",
        "#df.dropna()"
      ],
      "metadata": {
        "id": "ziFWX2hNDnYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Valores Únicos e Duplicados**"
      ],
      "metadata": {
        "id": "NTN_Sp44EB-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se os dados são únicos na coluna 'id'\n",
        "# Pelo fato de ter aparecido 'false', significa que temos dados duplicados\n",
        "print(\"A coluna id possui valores únicos? Resposta:\", df.select(\"id\").distinct().count() == df.count())"
      ],
      "metadata": {
        "id": "sNZtvEaUENA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se os dados são únicos na coluna 'sobrenome'\n",
        "# Pelo fato de ter aparecido 'false', significa que temos dados duplicados\n",
        "print(\"A coluna sobrenome possui valores únicos? Resposta:\", df.select(\"sobrenome\").distinct().count() == df.count())"
      ],
      "metadata": {
        "id": "ItgAOeeuErqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando dados duplicados no conjunto de dados\n",
        "df.orderBy(\"sobrenome\").show()"
      ],
      "metadata": {
        "id": "dTsZ6aCkFBV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a quantidade de sobrenomes repetidos na base de dados em ordem decrescente\n",
        "df.groupBy(\"sobrenome\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "id": "tUMNnxmUFZJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a quantidade de sobrenomes repetidos na base de dados\n",
        "df.groupBy(\"sobrenome\").count().show()"
      ],
      "metadata": {
        "id": "fR3fORyAGPnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando pelo nome\n",
        "df.filter(df[\"sobrenome\"] == \"Piccio\").show()"
      ],
      "metadata": {
        "id": "Ux1H-rikGUDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando o filtro da familia Piccio\n",
        "df_filtro1 = df.filter(df[\"sobrenome\"] == \"Piccio\")"
      ],
      "metadata": {
        "id": "5K09pyyKGyDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrando resultado do filtro\n",
        "df_filtro1.show()"
      ],
      "metadata": {
        "id": "ZDJuu00AG5tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o tamanho do DataFrame (linhas, colunas)\n",
        "print((df.count(), len(df.columns)))"
      ],
      "metadata": {
        "id": "RuWGsXSAHBKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminando valores duplicados na coluna sobrenome\n",
        "df = df.dropDuplicates(['sobrenome'])"
      ],
      "metadata": {
        "id": "FJU7sWcJHF5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando o tamanho do DataFrame (linhas, colunas)\n",
        "print((df.count(), len(df.columns)))"
      ],
      "metadata": {
        "id": "0FWGeghZHQvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtrar as linhas onde encerrou_conta é igual a 0\n",
        "encerrou_conta_0 = df.filter(df.encerrou_conta == 0)"
      ],
      "metadata": {
        "id": "HTiG34zSlTjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar as linhas onde encerrou_conta é igual a 1\n",
        "encerrou_conta_1 = df.filter(df.encerrou_conta == 1)"
      ],
      "metadata": {
        "id": "nBlHUF-zlVUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulação\n",
        "df.drop(\"numero_linha\", \"id\").show()"
      ],
      "metadata": {
        "id": "vybPZ6hnlxyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicação\n",
        "df = df.drop(\"numero_linha\", \"id\")"
      ],
      "metadata": {
        "id": "TB_RWD_8l2jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação\n",
        "df.show()"
      ],
      "metadata": {
        "id": "Ds26reOXl5r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionando colunas\n",
        "df.select(\"genero\",\"pontuacao_credito\", \"localizacao\", \"saldo\").show()"
      ],
      "metadata": {
        "id": "zyB-2CkFl8sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caso queira usar: Selecionando colunas\n",
        "df_selec = df.select(\"genero\",\"pontuacao_credito\", \"localizacao\", \"saldo\")"
      ],
      "metadata": {
        "id": "wTaS1n_3mj9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando\n",
        "df_selec.show()"
      ],
      "metadata": {
        "id": "zACc8E1bmm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tradução de Categorias**"
      ],
      "metadata": {
        "id": "u_B6ylHUoZJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "rpDZcF8Iogvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A expressão rdd.map(lambda x: x[0]).collect() em PySpark faz o seguinte:\n",
        "\n",
        "*  RDD (rdd): Representa um Resilient Distributed Dataset, uma estrutura de dados fundamental em PySpark, que permite operações distribuídas.\n",
        "\n",
        "*  map(lambda x: x[0]): Aplica uma função lambda a cada elemento do RDD, onde lambda x: x[0] extrai o primeiro elemento de cada tupla ou lista x.\n",
        "\n",
        "*  collect(): Coleta todos os elementos do RDD de volta para o driver (o ambiente principal onde o código é executado), retornando uma lista de Python contendo todos os elementos processados pelo map.\n",
        "\n",
        "Portanto, rdd.map(lambda x: x[0]).collect() retorna uma lista com o primeiro elemento de cada elemento do RDD rdd"
      ],
      "metadata": {
        "id": "wVr_WXm-ou3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação de valores unicos\n",
        "sorted(df.select(\"localizacao\").distinct().rdd.map(lambda x: x[0]).collect())"
      ],
      "metadata": {
        "id": "N-Cs8OxTnf4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação de valores unicos\n",
        "sorted(df.select(\"genero\").distinct().rdd.map(lambda x: x[0]).collect())"
      ],
      "metadata": {
        "id": "4MVfX427pHVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
